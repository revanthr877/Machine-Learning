{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"/kaggle/input/bayesian-classifier/week4_data_pima_indian.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics","metadata":{"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/bayesian-classifier/week4_data_pima_indian.csv\")\nfeature_col_names = ['num_preg', 'glucose_conc', 'diastolic_bp', 'thickness', 'insulin', 'bmi', 'diab_pred', 'age']\npredicted_class_names = ['diabetes']","metadata":{"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"\nX = df[feature_col_names].values \ny = df[predicted_class_names].values","metadata":{"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"\nprint(df.head)\nxtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.33)\n\nprint ('\\n The total number of Training Data :',ytrain.shape)\nprint ('\\n The total number of Test Data :',ytest.shape)","metadata":{"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"<bound method NDFrame.head of      num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  \\\n0           6           148            72         35        0  33.6   \n1           1            85            66         29        0  26.6   \n2           8           183            64          0        0  23.3   \n3           1            89            66         23       94  28.1   \n4           0           137            40         35      168  43.1   \n..        ...           ...           ...        ...      ...   ...   \n763        10           101            76         48      180  32.9   \n764         2           122            70         27        0  36.8   \n765         5           121            72         23      112  26.2   \n766         1           126            60          0        0  30.1   \n767         1            93            70         31        0  30.4   \n\n     diab_pred  age  diabetes  \n0        0.627   50         1  \n1        0.351   31         0  \n2        0.672   32         1  \n3        0.167   21         0  \n4        2.288   33         1  \n..         ...  ...       ...  \n763      0.171   63         0  \n764      0.340   27         0  \n765      0.245   30         0  \n766      0.349   47         1  \n767      0.315   23         0  \n\n[768 rows x 9 columns]>\n\n The total number of Training Data : (514, 1)\n\n The total number of Test Data : (254, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"clf = GaussianNB().fit(xtrain,ytrain.ravel())\npredicted = clf.predict(xtest)\npredictTestData= clf.predict([[6,148,72,35,0,33.6,0.627,50]])","metadata":{"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print('\\n Confusion matrix')\nprint(metrics.confusion_matrix(ytest,predicted))\n\nprint('\\n Accuracy of the classifier is',metrics.accuracy_score(ytest,predicted))\n\nprint('\\n The value of Precision :', metrics.precision_score(ytest,predicted))\n\nprint('\\n The value of Recall :', metrics.recall_score(ytest,predicted))\n\nprint(\"\\n Predicted Value for individual Test Data:\", predictTestData)","metadata":{"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"\n Confusion matrix\n[[138  41]\n [ 31  44]]\n\n Accuracy of the classifier is 0.7165354330708661\n\n The value of Precision : 0.5176470588235295\n\n The value of Recall : 0.5866666666666667\n\n Predicted Value for individual Test Data: [1]\n","output_type":"stream"}]}]}